# -*- coding: utf-8 -*-
"""CCFD_for_seperate_KNN.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1kRxvlhQpvAHq1vpddbkamgxpnAdkXDlX
"""

#Importing the basic libraries
from colabcode import ColabCode
from django.forms import ModelMultipleChoiceField, modelformset_factory
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import plotly.offline as py
from plotly import tools
py.init_notebook_mode(connected=True)
import plotly.graph_objs as go
from sklearn.model_selection import train_test_split
import warnings
warnings.filterwarnings('ignore')

#Reading the dataset 
df = pd.read_csv(creditcard.csv)

#Describe the dataset to get rough idea about the data 
df.describe()

#Well let's see all the columns in the dataset 
df.columns

#A brief look at the initial rows of the dataset 
df.head()

#It's good to shuffle the datset 
df = df.sample(frac=1, random_state=42).reset_index(drop=True)

#Let's take a look again 
df.head()

#Non fradulant cases
df.Class.value_counts()[0]

#Fradulant cases 
df.Class.value_counts()[1]

print('Percentage of correct transactions: {}'.format((df.Class.value_counts()[0]/df.shape[0])*100))

print('Percentage of fradulent transactions: {}'.format((df.Class.value_counts()[1]/df.shape[0])*100))

#Let's visualize the distribution of the classes (0 means safe and 1 means fraudulent)
import seaborn as sns
colors = ['green', 'red']

sns.countplot('Class', data=df, palette=colors)
plt.title('Normal v/s Fraudulent')

#Now let's map how much a feature affects our class 
cor = df.corr()
fig = plt.figure(figsize = (12, 9))

#Plotting the heatmap
sns.heatmap(cor, vmax = 0.7)
plt.show()

cor.shape

#This is how much a each feature affects the our class 
cor.iloc[-1,:]

#We need to delet the least and greatest values 
#From above analysis I've selected the following features 
#Note that I've included the class variable also because I intend to create a new dataframe using the new features
new_features=['V1','V3','V4','V7','V10','V11','V12','V14','V16','V17','V18','Class']

#Let's plot a heatmap again and see the relationship
cor = df[new_features].corr()
fig = plt.figure(figsize = (12, 9))

#Plotting the heatmap
sns.heatmap(cor, vmax = 0.7)
plt.show()

#We see that the class rows and columns are darker and brighter 
#This means that all the variables in our new dataset have a significant affect

#Now splitting the dataset into the dependent variable(y) and independent variales(x)
x=df[new_features].iloc[:,:-1].values
y=df[new_features].iloc[:,-1].values

#Withoud reducing the features 
#x=df.iloc[:,:-1].values
#y=df.iloc[:,-1].values
#Feel free to try using all the features :)

x.shape

y.shape

x[:5]

y[:5]

#Spliting the data into train and test sets 
from sklearn.model_selection import train_test_split
x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.25, random_state = 0)

#Let's see how many safe and fraudulent cases are there in training set 
safe_train=(y_train==0).sum()
fraud_train=(y_train==1).sum()
print("Safe: {} \nFraud: {}".format(safe_train,fraud_train))

#Let's see how many safe and fraudulent cases are there in test set 
safe_test=(y_test==0).sum()
fraud_test=(y_test==1).sum()
print("Safe: {} \nFraud: {}".format(safe_test,fraud_test))

"""##  KNN


"""

from sklearn.neighbors import KNeighborsClassifier 
from sklearn.metrics import confusion_matrix
from sklearn.metrics import classification_report
clf = KNeighborsClassifier(n_neighbors = 5, metric = 'minkowski', p = 2) 
clf.fit(x_train, y_train)
y_pred = clf.predict(x_test)
print("Training Accuracy: ",clf.score(x_train, y_train))
print("Testing Accuracy: ",clf.score(x_test, y_test))
cm = confusion_matrix(y_test, y_pred)
print(cm)
print(classification_report(y_test,y_pred))


from joblib import dump
dump(model,'./../ccfd/model.joblib')
